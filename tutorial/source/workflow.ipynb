{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-dimensional Bayesian workflow\n",
    "\n",
    "This tutorial describes a workflow for incrementally building pipelines to analyze high-dimensional data in Pyro. This workflow has evolved over a few years of applying Pyro to models with $10^5$ or more latent variables. While the individual components of the pipeline deserve their own tutorials, this tutorial focuses on incrementally combining those components. Workflow efficiency demands that code changes to upstream components dot break previous coding effort on downstream components. Pyro's approaches to this challenge include strategies for variational approximations ([pyro.infer.autoguide](https://docs.pyro.ai/en/stable/infer.autoguide.html)) and strategies for transforming model coordinate systems to improve geometry ([pyro.infer.reparam](https://docs.pyro.ai/en/stable/infer.reparam.html)).\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- For simple black-box guides, try using components in [pyro.infer.autoguide](http://docs.pyro.ai/en/stable/infer.autoguide.html).\n",
    "- For more complex guides, try using components in [pyro.contrib.easyguide](http://docs.pyro.ai/en/stable/contrib.easyguide.html).\n",
    "- Decorate with `@easy_guide(model)`.\n",
    "- Select multiple model sites using `group = self.group(match=\"my_regex\")`.\n",
    "- Guide a group of sites by a single distribution using `group.sample(...)`.\n",
    "- Inspect concatenated group shape using `group.batch_shape`, `group.event_shape`, etc.\n",
    "- Use `self.plate(...)` instead of `pyro.plate(...)`.\n",
    "- To be compatible with subsampling, pass the `event_dim` arg to `pyro.param(...)`.\n",
    "- To MAP estimate model site \"foo\", use `foo = self.map_estimate(\"foo\")`.\n",
    "\n",
    "#### Table of contents\n",
    "\n",
    "- [Modeling time series data](#Modeling-time-series-data)\n",
    "- [Writing a guide without EasyGuide](#Writing-a-guide-without-EasyGuide)\n",
    "- [Using EasyGuide](#Using-EasyGuide)\n",
    "- [Amortized guides](#Amortized-guides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Consider the problem of sampling from the posterior distribution of a probabilistic model with $10^5$ or more continuous latent variables, but whose data fits entirely in memory.\n",
    "(For larger datasets, consider [amortized variational inference]().) Inference in such high-dimensional models can be challenging even when posteriors are known to be unimodal or even log-concave, due to strong correlations among latent variables.\n",
    "\n",
    "To perform inference in such high-dimensional models in Pyro, we have evolved a [workflow](https://arxiv.org/abs/2011.01808) to incrementally build data analysis pipelines combining variational inference, MCMC, reparametrization effects, and ad-hoc initialization strategies. Our workflow is summarized as a sequence of steps, where validation after any step might suggest backtracking to change design decisions at a previous step.\n",
    "\n",
    "1. Clean the data.\n",
    "2. Create a generative model.\n",
    "3. Create an initialization heuristic.\n",
    "4. Sanity check using MAP or mean-field inference.\n",
    "5. Reparameterize the model, evaluating results under mean field VI.\n",
    "6. Customize the variational family (autoguides, easyguides, custom guides).\n",
    "7. Optionally draw posterior samples via reparameterized, variationally preconditioned MCMC.\n",
    "\n",
    "The crux to workflow efficiency is to ensure backtracking doesn't break the pipeline. That is, after one builds a number of pipeline stages, decides through validation that an early pipeline stage needs to be changed, and changes that early stage, one would like to minimize code changes needed in downstream stages. The remainder of this tutorial describes these steps individually, then describes nuances of interactions among stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.contrib.easyguide import easy_guide\n",
    "from pyro.optim import Adam\n",
    "from torch.distributions import constraints\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.7.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
