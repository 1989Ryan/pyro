{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pyro.contrib.funsor`: a new backend for Pyro (pt. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import funsor\n",
    "\n",
    "from pyro import set_rng_seed as pyro_set_rng_seed\n",
    "from pyro.ops.indexing import Vindex\n",
    "from pyro.poutine.messenger import Messenger\n",
    "\n",
    "funsor.set_backend(\"torch\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "pyro_set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In part 1 of this tutorial, we were introduced to the new `pyro.contrib.funsor` backend for Pyro.\n",
    "\n",
    "Here we'll look at how to use the components in `pyro.contrib.funsor` to implement a variable elimination inference algorithm from scratch. As before, we'll use `pyroapi` so that we can write our model with standard Pyro syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.contrib.funsor\n",
    "import pyroapi\n",
    "from pyroapi import infer, handlers, ops, optim, pyro\n",
    "from pyroapi import distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the following model throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "\n",
    "    p = pyro.param(\"probs\", lambda: torch.rand((3, 3)), constraint=constraints.simplex)\n",
    "    locs_mean = pyro.param(\"locs_mean\", lambda: torch.ones((3,)))\n",
    "    locs = pyro.sample(\"locs\", dist.Normal(locs_mean, 1.).to_event(1))\n",
    "    print(\"locs\", locs.shape)\n",
    "\n",
    "    x = 0\n",
    "    for i in pyro.markov(range(len(data))):\n",
    "        x = pyro.sample(\"x{}\".format(i), dist.Categorical(p[x]), infer={\"enumerate\": \"parallel\"})\n",
    "        print(\"x{}\".format(i), x.shape)\n",
    "        pyro.sample(\"y{}\".format(i), dist.Normal(Vindex(locs)[..., x], 1.), obs=data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerating discrete variables\n",
    "\n",
    "Our first step is to implement an effect handler that performs parallel enumeration of discrete latent variables. We'll do that by constructing a `funsor.Tensor` representing the support of each discrete latent variable and using the new `pyro.to_data` primitive from part 1 to convert it to a `torch.Tensor` with the appropriate shape.\n",
    "\n",
    "In part 1 we also saw that it was necessary to provide the number of \"visible\" dimensions used in a block of code by calling `_DIM_STACK.set_first_available_dim`. To avoid this tedious bit of bookkeeping, we'll have our enumeration effect handler inherit from the `BaseEnumMessenger` class provided in `pyro.contrib.funsor`, which takes care of setting `first_available_dim` and resetting it after the handler has exited. Our enumeration handler's constructor will take a `first_available_dim` keyword argument because of this, just like Pyro's `poutine.enum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.contrib.funsor.handlers.named_messenger import BaseEnumMessenger\n",
    "\n",
    "class EnumMessenger(BaseEnumMessenger):\n",
    "    \n",
    "    # although our __init__ does not do anything extra, we specify it explicitly here\n",
    "    # to show the argument that needs to be passed to `BaseEnumMessenger.__init__`.\n",
    "    def __init__(self, first_available_dim=-1):\n",
    "        super().__init__(first_available_dim=first_available_dim)\n",
    "    \n",
    "    @pyroapi.pyro_backend(\"contrib.funsor\")  # necessary since we invoke pyro.to_data\n",
    "    def _pyro_sample(self, msg):\n",
    "        if msg[\"done\"] or msg[\"is_observed\"] or msg[\"infer\"].get(\"enumerate\") != \"parallel\":\n",
    "            return\n",
    "\n",
    "        raw_value = msg[\"fn\"].enumerate_support(expand=False)\n",
    "        size = raw_value.numel()\n",
    "        funsor_value = funsor.Tensor(\n",
    "            raw_value.squeeze(), OrderedDict([(msg[\"name\"], funsor.bint(size))]), size)\n",
    "        \n",
    "        msg[\"value\"] = pyro.to_data(funsor_value)\n",
    "        msg[\"done\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing a model across multiple samples\n",
    "\n",
    "Next, since our priors over global variables are continuous and cannot be enumerated exactly, we will implement an effect handler that uses a global dimension to draw multiple samples in parallel from the model.\n",
    "\n",
    "Recall that in part 1 we saw that `DimType.GLOBAL` dimensions must be deallocated manually or they will persist until the final effect handler has exited. This low-level detail is taken care of automatically by the `GlobalNameMessenger` handler provided in `pyro.contrib.funsor` as a base class for any effect handlers that allocate global dimensions. Our vectorization effect handler will inherit from this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.poutine.broadcast_messenger import BroadcastMessenger\n",
    "from pyro.poutine.indep_messenger import CondIndepStackFrame\n",
    "\n",
    "from pyro.contrib.funsor.handlers.named_messenger import GlobalNamedMessenger\n",
    "from pyro.contrib.funsor.handlers.runtime import DimType\n",
    "\n",
    "class VectorizeMessenger(GlobalNamedMessenger):\n",
    "    \n",
    "    def __init__(self, size, name=\"_PARTICLES\"):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.size = size\n",
    "        self._indices = funsor.Tensor(\n",
    "            torch.arange(0, self.size),\n",
    "            OrderedDict([(self.name, funsor.bint(self.size))])\n",
    "        )\n",
    "\n",
    "    @pyroapi.pyro_backend(\"contrib.funsor\")\n",
    "    def __enter__(self):\n",
    "        super().__enter__()  # do this first to take care of global dim recycling\n",
    "        # Here we indicate that the vectorization dimension is a DimType.GLOBAL dimension,\n",
    "        # as opposed to a DimType.VISIBLE dimension that we would use in pyro.plate\n",
    "        indices = pyro.to_data(self._indices, dim_type=DimType.GLOBAL)\n",
    "        # extract the dimension allocated by to_data to match plate's current behavior\n",
    "        self.dim, self.indices = -indices.dim(), indices.squeeze()\n",
    "        return self\n",
    "\n",
    "    def _pyro_sample(self, msg):\n",
    "        frame = CondIndepStackFrame(self.name, self.dim, self.size, 0)\n",
    "        msg[\"cond_indep_stack\"] = (frame,) + msg[\"cond_indep_stack\"]\n",
    "        BroadcastMessenger._pyro_sample(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing an ELBO with variable elimination\n",
    "\n",
    "Our final effect handler will build up a lazy Funsor expression for the marginal likelihood, the loss function we'll be using to train our approximate posterior over the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogJointMessenger(Messenger):\n",
    "\n",
    "    @pyroapi.pyro_backend(\"contrib.funsor\")\n",
    "    def __enter__(self):\n",
    "        self.log_joint = pyro.to_funsor(0., funsor.reals())\n",
    "        return super().__enter__()\n",
    "\n",
    "    @pyroapi.pyro_backend(\"contrib.funsor\")\n",
    "    def _pyro_post_sample(self, msg):\n",
    "        with funsor.interpreter.interpretation(funsor.terms.lazy):\n",
    "            funsor_dist = pyro.to_funsor(msg[\"fn\"], output=funsor.reals())\n",
    "            self.log_joint += funsor_dist(value=pyro.to_funsor(msg[\"value\"], funsor_dist.inputs[\"value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the actual loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyroapi.pyro_backend(\"contrib.funsor\")\n",
    "def log_z(model, *args):\n",
    "    with LogJointMessenger() as tr, EnumMessenger(), VectorizeMessenger(20):\n",
    "        model(*args)\n",
    "\n",
    "    with funsor.interpreter.interpretation(funsor.terms.lazy):\n",
    "        prod_vars = frozenset({\"_PARTICLES\"})\n",
    "        sum_vars = frozenset(tr.log_joint.inputs) - prod_vars\n",
    "        expr = tr.log_joint.reduce(funsor.ops.logaddexp, sum_vars).reduce(funsor.ops.add, prod_vars)\n",
    "\n",
    "    return pyro.to_data(funsor.optimizer.apply_optimizer(expr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Finally, with all this machinery implemented, we can perform inference in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 torch.Size([3, 1])\n",
      "x1 torch.Size([3, 1, 1])\n",
      "x2 torch.Size([3, 1])\n",
      "x3 torch.Size([3, 1, 1])\n",
      "x4 torch.Size([3, 1])\n",
      "x5 torch.Size([3, 1, 1])\n",
      "x6 torch.Size([3, 1])\n",
      "x7 torch.Size([3, 1, 1])\n",
      "x8 torch.Size([3, 1])\n",
      "x9 torch.Size([3, 1, 1])\n",
      "tensor(-333.6899, grad_fn=<SumBackward0>) (tensor([[ 3.1844,  1.0427, -4.2271],\n",
      "        [ 0.4608,  0.1888, -0.6496],\n",
      "        [-1.3316, -0.3965,  1.7282]]), tensor([ 7.4881,  5.9110, 17.3450]))\n"
     ]
    }
   ],
   "source": [
    "data = [torch.tensor(1.)] * 10\n",
    "log_marginal = log_z(model, data)\n",
    "params = [pyro.param(\"probs\").unconstrained(), pyro.param(\"locs_mean\").unconstrained()]\n",
    "print(log_marginal, torch.autograd.grad(log_marginal, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
